\section{Arrays}
As was mentioned above, arrays are used heavily in software analysis
applications, and reasoning about arrays has been a major bottleneck
in many examples. STP's input language supports one-dimensional
(non-extensional) arrays~\cite{stumparray} that are indexed by
bit-vectors and contain bit-vectors.  The operations on arrays are
$\stpread(A, i)$, which returns the value at location $A[i]$ where $A$
is an array and $i$ is an index expression of the correct type, and
$\stpwrite(A, i, v)$, which returns a new array with the same value as
$A$ at all indices except possibly $i$, where it has the value $v$.
The value of a $\stpread$ is a bit-vector, which can appear as an
operand to any operation or predicate that operates on bit-vectors.
The value of an array variable or an array write has an array type,
and may only appear as the first operand of a $\stpread$ or
$\stpwrite$, or as the then or else operand of an if-then-else.  In
particular, values of an array type cannot appear in an equality or
any other predicate.

In the unoptimized mode, STP reduces all formulas to an
equisatisfiable form that contains no array $\stpread$s or
$\stpwrite$s, using three transformations.  (In the following, the
expression $\stpite(c_1,e_1,e_2)$ is shorthand for {\it if $c_1$ then
$e_1$ else $e_2$ endif}.)  These transformations are all standard.

The {\bf Ite-lifting\/} transformation converts
$\stpread(\stpite(c, \stpwrite(A, i, v), e), j)$ to
$\stpite(c,$ $\stpread(\stpwrite(A, i, v), j), e)$.  
(There is
a similar transformation when the $\stpwrite$ is in the ``else'' part
of the $\stpite$.)  The {\bf read-over-write} transformation
eliminates all write terms by transforming 
$\stpread(\stpwrite(A, i, v), j)$ to $\stpite(i=j, v, \stpread(A, j))$.  
Finally, the {\bf read
elimination} transformation eliminates $\stpread$ terms by introducing
a fresh bit-vector variable for each such expression, and adding
more predicates to ensure consistency.  Specifically, whenever a
term $\stpread(A, i)$ appears, it is replaced by a fresh variable $v$,
and new predicates are conjoined to the formula $i = j \Rightarrow v =
w$ for all variables $w$ introduced in place of read terms
$\stpread(A, j)$, having the same array term as first operand. As an
example of this transformation, the simple formula $(\stpread(A, 0) =
0) \wedge (\stpread(A, i) = 1)$ would be transformed to
$v_1 = 0 \wedge v_2 = 1 \wedge (i = 0 \Rightarrow v_1 = v_2)$.
The formula of the form $(i = 0 \Rightarrow v_1 = v_2)$ is 
called an {\it array read axiom}.

\subsection{Optimizing array reads}

Read elimination, as described above, expands each formula by up to
$n(n-1)/2$ nodes, where $n$ is the number of syntactically distinct
index expressions. Unfortunately, software analysis applications can
produce thousands of reads with variable indices, resulting in a
lethal blow-up when this transformation is applied.  
While this blow-up seems unavoidable in the worst case,
appropriate procrastination leads to practical solutions for many very
large problems. Two optimizations which have been very
effective are {\it array substitution} and abstraction-refinement for
reads, which we call {\it read refinement}.

The array substitution optimization reduces the number of array
variables by substituting out all constraints of the form $\stpread(A,
c) = e_1$, where $c$ is a constant and $e_1$ does not contain another
array read.  Programs often index into arrays or memory using constant
indexes, so this is a case that occurs often in practice.

The optimization has two passes. The first pass builds a substitution
table with the left-hand-side of each such equation ($\stpread(A, c)$)
as the key and the right-hand-side ($e_1$) as the value, and then
deletes the equation from the input query. The second pass over the
expression replaces each occurrence of a key by the corresponding
table entry. Note that for soundness, if a second
equation is encountered whose left-hand-side is already in the table, 
the second equation is not deleted and the table is not changed.
For example, if STP saw $\stpread(A, c) = e_1$ then $\stpread(A, C) = e_2$,
the second formula would not be deleted and would later be simplified
to $e_1 = e_2$.

The second optimization, {\it read refinement}, delays the translation
of array {\stpread}s with non-constant indexes in the hope of avoiding
read elimination blowup. Its main trick is to solve a less-expensive
approximation of the formula, check the result in the original
formula, and try again with a more accurate approximation if the
result is incorrect.

Read formulas are abstracted by performing read elimination,
{\em i.e.,} replacing reads with new variables, but not adding the array read
axioms.  This abstracted formula is processed by the remaining
stages of STP.  As discussed in the overview, if the result is
unsatisfiable, that result is correct and can be returned immediately
from STP.  If not, the abstract model found by STP is converted to a
concrete model and the original formula is evaluated with respect to
that model.  If the result is $\stptrue$, the answer is correct and
STP returns that model.  Otherwise, some of the array read axioms from
read elimination are added to the formula and STP is asked to satisfy
the modified formula.
This iteration repeats until a correct result is found,
which is guaranteed to happen (if memory and time are not exhausted)
because all of the finitely many array read axioms will eventually be
added in the worst case.

The choice of which array read axioms to add during refinement is a
heuristic that is important to the success of the method.  A policy
that seems to work well is to find a non-constant array index term for
which at least one axiom is violated, then add all of the violated
axioms involving that term.  Adding at least one false axiom during
refinement guarantees that STP will not find the same false model more
than once.  Adding all the axioms for a particular term seems
empirically to be a good compromise between adding just one formula,
which results in too many iterations, and adding all formulas, which
eliminates all abstraction after the first failure.

For example, suppose STP is given the formula $(\stpread(A, 0) = 0)
\wedge (\stpread(A, i) = 1)$.  STP would first apply the substitution
optimization by deleting $\stpread(A, 0) = 0$ from the formula, and
inserting the pair $(\stpread(A, 0), 0)$ in the substitution
table. Then, it would replace $\stpread(A, i)$ by a new variable
$v_i$, thus generating the under-constrained formula $v_i = 1$.
Suppose STP finds the solution $i = 1$ and $v_i = 1$.

STP then translates the solution to the variables of the original
formula to get $(\stpread(A, 0) = 0)$ $\wedge$ $\stpread(A, 1) = 1)$.
This solution is satisfiable in the original formula as well, so STP
terminates since it has found a true satisfying assignment.

However, suppose that STP finds the solution $i = 0$ and $v_i = 1$.
Under this solution, the original formula eventually evaluates to
$\stpread(A,0) = 0 \wedge \stpread(A, 0) = 1$, which after
substitution gives $0=1$. Hence, the solution to the under-constrained
formula is not a solution to the original formula.

In this case, STP adds the array read axiom $i=0 \Rightarrow
\stpread(A, i) = \stpread(A, 0)$.  When this formula is checked, the
result must be correct because the new formula includes the complete
set of array read axioms.

\subsection{Optimizing array writes}

Efficiently dealing with array writes is crucial to STP's utility in
software applications, some of which produce deeply nested write terms
when there are many successive assignments to indices of the same array.
The {\bf read-over-write} transformation
creates a performance bottleneck by destroying sharing of subterms,
creating an unacceptable blow-up in DAG size.
Consider the simple formula:
$\stpread(\stpwrite(A,i,v),j) = \stpread(\stpwrite(A,i,v),k)$, in
which the $\stpwrite$ term is shared.

The {\bf read-over-write} transformation translates this to
$\stpite(i=j,v,\stpread(A,j)) = \stpite(i=k,v,\stpread(A,k))$.  When
applied recursively to the deeply nested $\stpwrite$ terms, it
essentially creates a new copy of the entire DAG of write terms for
every distinct read index, which exhausts memory in large examples.

Once again, the procrastination principle applies.  
The {\bf read-over-write} transformation is delayed until after other
simplification and solving transformations are performed,
except in special cases like $\stpread(\stpwrite(A, i, v), i+1)$,
where the read and write indices simplify to terms that are 
always equal or not equal.
In practice, the simple transformations convert many index terms to
constants.  The {\bf read-over-write} transformation is applied
in a subsequent phase.  When that happens, the formula is smaller
and contains more constants.
This simple optimization is enormously effective, enabling STP to
solve many very large problems with nested writes that it is otherwise
unable to do.

Abstraction and refinement can also be used on write expressions, when
the previous optimization leaves large numbers of $\stpread$s and
$\stpwrite$s, leading to major speed-ups on some large formulas.
For this optimization, array read-over-write terms are
replaced by new variables to yield a conjunction of formulas that is
equisatisfiable to the original set.  The example above is transformed
to:
\[
\begin{array}{rcl}
v_1 &=& v_2 \\
v_1 &=& \stpite(i=j,v,\stpread(A,j)) \\
v_2 &=& \stpite(i=k,v,\stpread(A,k))
\end{array}
\]
where the last two formulas are called {\it array write axioms}. For
the abstraction, the array write axioms are omitted, and the
abstracted formula $v_1 = v_2$ is processed by the remaining phases of
STP.  As with array reads, the refinement loop iterates only if STP
finds a model of the abstracted formula that is also not a model of
the original formula. Write axioms are added to the abstracted
formula, and the refinement loop iterates with the additional axioms
until a definite result is produced. Although, this technique leads to
improvement in certain cases, the primary problem with it is that the
number of iterations of the refinement loop is sometimes very large.
